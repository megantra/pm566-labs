---
title: "lab06"
author: "Megan Tran"
date: '`September 28, 2022'
output: github_document
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r install-libraries}
library(tidytext)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(forcats)
```

## 1. Read in the data
```{r read-data, cache=TRUE}
if (!file.exists("mtsamples.csv")) {
download.file("https://raw.githubusercontent.com/USCbiostats/data-science-data/master/00_mtsamples/mtsamples.csv", "mtsamples.csv", method="libcurl", timeout = 60) 
}
mts <- read.csv("mtsamples.csv") 
str(mts)
mts <- as_tibble(mts)
mts
```

##Question 1: What specialties do we have?

We can use count() from dplyr to figure out how many records are there per specialty?

```{r medical-specialties}
specialties <-
    mts %>%
    count(medical_specialty)

specialties %>%
  arrange(desc(n)) %>%
knitr::kable()
```

There are 'r nrow(specialties)' medical specialties.

```{r barplot-of-specialty-counts}
specialties %>%
  top_n(10) %>%
  ggplot( aes(x = n, y = fct_reorder(medical_specialty,n))) + 
    geom_col()
```

The distribution is not at all uniform.

##Question 2 Visualize the top 20 most frequent words in the transcription column

Tokenize the the words in the transcription column
Count the number of times each token appears
Visualize the top 20 most frequent words

```{r token-transcription, cache = TRUE}
mts %>%
  unnest_tokens(word, transcription) %>%
  #anti_join(stop_words, by = c("word")) %>%
  count(word, sort = TRUE) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```

There are a lot of stopwords here, non-specific to medical text. 
We do see "patient", phew!

##Question 3 Redo analysis in Q2 and remove stopwords.

Redo visualization but remove stopwords first
Bonus points if you remove numbers as well

```{r , cache=TRUE}
mts %>%
  unnest_tokens(word, transcription) %>%
  count(word, sort = TRUE) %>%
  anti_join(stop_words, by = c("word")) %>%
  # use regular expression to filter out numbers
  filter( !grepl(pattern = "^[0-9]+$",x = word)) %>%
  top_n(20, n) %>%
  ggplot(aes(n, fct_reorder(word, n))) +
  geom_col()
```


What do we see know that we have removed stop words? Does it give us a better idea of what the text is about?



